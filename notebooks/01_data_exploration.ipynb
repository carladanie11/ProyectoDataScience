{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de4a9519",
   "metadata": {},
   "source": [
    "# Paso1: Seleccion y preparacion del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd38485b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descargando yellow_tripdata_2016-01.parquet...\n",
      "‚úÖ yellow_tripdata_2016-01.parquet descargado\n",
      "Descargando yellow_tripdata_2016-02.parquet...\n",
      "‚úÖ yellow_tripdata_2016-02.parquet descargado\n",
      "Descargando yellow_tripdata_2016-03.parquet...\n",
      "‚úÖ yellow_tripdata_2016-03.parquet descargado\n",
      "Descargando yellow_tripdata_2016-04.parquet...\n",
      "‚úÖ yellow_tripdata_2016-04.parquet descargado\n",
      "Descargando yellow_tripdata_2016-05.parquet...\n",
      "‚úÖ yellow_tripdata_2016-05.parquet descargado\n",
      "Descargando yellow_tripdata_2016-06.parquet...\n",
      "‚úÖ yellow_tripdata_2016-06.parquet descargado\n",
      "üéâ Todas las descargas completadas!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "\n",
    "# URLs de los archivos\n",
    "urls = [\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-01.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-02.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-03.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-04.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-05.parquet\",\n",
    "    \"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2016-06.parquet\"\n",
    "]\n",
    "\n",
    "# Funci√≥n para descargar archivo\n",
    "def download_file(url, filename):\n",
    "    print(f\"Descargando {filename}...\")\n",
    "    response = requests.get(url, stream=True)\n",
    "    with open(filename, 'wb') as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "    print(f\"‚úÖ {filename} descargado\")\n",
    "\n",
    "# Descargar todos los archivos\n",
    "for url in urls:\n",
    "    filename = url.split('/')[-1]  # Extrae el nombre del archivo\n",
    "    if not os.path.exists(filename):\n",
    "        download_file(url, filename)\n",
    "    else:\n",
    "        print(f\"‚è≠Ô∏è  {filename} ya existe, saltando...\")\n",
    "\n",
    "print(\"üéâ Todas las descargas completadas!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2a0563",
   "metadata": {},
   "source": [
    "Verificaci√≥n de Archivos Descargados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "554e076a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== VERIFICACI√ìN DE ARCHIVOS ===\n",
      "‚úÖ yellow_tripdata_2016-01.parquet - 144.2 MB\n",
      "‚úÖ yellow_tripdata_2016-02.parquet - 150.8 MB\n",
      "‚úÖ yellow_tripdata_2016-03.parquet - 162.1 MB\n",
      "‚úÖ yellow_tripdata_2016-04.parquet - 157.9 MB\n",
      "‚úÖ yellow_tripdata_2016-05.parquet - 158.1 MB\n",
      "‚úÖ yellow_tripdata_2016-06.parquet - 149.0 MB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Verificar archivos descargados\n",
    "archivos_esperados = [\n",
    "    \"yellow_tripdata_2016-01.parquet\",\n",
    "    \"yellow_tripdata_2016-02.parquet\", \n",
    "    \"yellow_tripdata_2016-03.parquet\",\n",
    "    \"yellow_tripdata_2016-04.parquet\",\n",
    "    \"yellow_tripdata_2016-05.parquet\",\n",
    "    \"yellow_tripdata_2016-06.parquet\"\n",
    "]\n",
    "\n",
    "print(\"=== VERIFICACI√ìN DE ARCHIVOS ===\")\n",
    "for archivo in archivos_esperados:\n",
    "    if os.path.exists(archivo):\n",
    "        size_mb = os.path.getsize(archivo) / (1024*1024)\n",
    "        print(f\"‚úÖ {archivo} - {size_mb:.1f} MB\")\n",
    "    else:\n",
    "        print(f\"‚ùå {archivo} - NO ENCONTRADO\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668f5c7a",
   "metadata": {},
   "source": [
    "Combinaci√≥n de Archivos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d6786f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Procesando SOLO Enero 2016 (muestra representativa)\n",
      "Registros originales: 10,905,067\n",
      "Muestra aleatoria: 500,000 registros\n",
      "Per√≠odo: 2016-01-01 00:00:00 a 2016-01-31 23:59:20\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "print(\"üéØ Procesando SOLO Enero 2016 (muestra representativa)\")\n",
    "\n",
    "# Cargar solo el primer archivo\n",
    "df = pd.read_parquet(\"yellow_tripdata_2016-01.parquet\")\n",
    "print(f\"Registros originales: {len(df):,}\")\n",
    "\n",
    "# Tomar muestra aleatoria de 500k registros \n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "sample_size = 500000\n",
    "\n",
    "if len(df) > sample_size:\n",
    "    df_sample = df.sample(n=sample_size, random_state=42)\n",
    "    print(f\"Muestra aleatoria: {len(df_sample):,} registros\")\n",
    "else:\n",
    "    df_sample = df\n",
    "    print(f\"Dataset completo: {len(df_sample):,} registros\")\n",
    "\n",
    "# Verificar distribuci√≥n temporal\n",
    "print(f\"Per√≠odo: {df_sample['tpep_pickup_datetime'].min()} a {df_sample['tpep_pickup_datetime'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c32a3",
   "metadata": {},
   "source": [
    "Creaci√≥n de Variable Target y Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "323e3ee9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚è±Ô∏è  Calculando duraci√≥n de viajes...\n",
      "Duraci√≥n promedio: 15.2 minutos\n",
      "Duraci√≥n mediana: 10.4 minutos\n",
      "Duraci√≥n m√≠nima: 0.0 minutos\n",
      "Duraci√≥n m√°xima: 31113.0 minutos\n",
      "‚ö†Ô∏è  Duraciones inv√°lidas (‚â§0): 549\n",
      "‚ö†Ô∏è  Duraciones extremas (>3h): 750\n"
     ]
    }
   ],
   "source": [
    "# Crear variable target: duraci√≥n del viaje\n",
    "print(\"‚è±Ô∏è  Calculando duraci√≥n de viajes...\")\n",
    "\n",
    "df_sample['trip_duration'] = (\n",
    "    df_sample['tpep_dropoff_datetime'] - df_sample['tpep_pickup_datetime']\n",
    ").dt.total_seconds()\n",
    "\n",
    "# Estad√≠sticas iniciales de duraci√≥n\n",
    "print(f\"Duraci√≥n promedio: {df_sample['trip_duration'].mean()/60:.1f} minutos\")\n",
    "print(f\"Duraci√≥n mediana: {df_sample['trip_duration'].median()/60:.1f} minutos\")\n",
    "print(f\"Duraci√≥n m√≠nima: {df_sample['trip_duration'].min()/60:.1f} minutos\")\n",
    "print(f\"Duraci√≥n m√°xima: {df_sample['trip_duration'].max()/60:.1f} minutos\")\n",
    "\n",
    "# Verificar valores problem√°ticos\n",
    "invalid_durations = (df_sample['trip_duration'] <= 0).sum()\n",
    "extreme_durations = (df_sample['trip_duration'] > 10800).sum()  # >3 horas\n",
    "print(f\"‚ö†Ô∏è  Duraciones inv√°lidas (‚â§0): {invalid_durations:,}\")\n",
    "print(f\"‚ö†Ô∏è  Duraciones extremas (>3h): {extreme_durations:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d72eac",
   "metadata": {},
   "source": [
    "Verificar Nombres de Columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58ae42f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç VERIFICANDO ESTRUCTURA DEL DATASET\n",
      "Columnas disponibles: ['VendorID', 'tpep_pickup_datetime', 'tpep_dropoff_datetime', 'passenger_count', 'trip_distance', 'RatecodeID', 'store_and_fwd_flag', 'PULocationID', 'DOLocationID', 'payment_type', 'fare_amount', 'extra', 'mta_tax', 'tip_amount', 'tolls_amount', 'improvement_surcharge', 'total_amount', 'congestion_surcharge', 'airport_fee', 'trip_duration']\n",
      "Total columnas: 20\n",
      "\n",
      "Primeras 3 filas:\n",
      "          VendorID tpep_pickup_datetime tpep_dropoff_datetime  \\\n",
      "10490098         1  2016-01-30 21:46:05   2016-01-30 22:10:42   \n",
      "2864959          2  2016-01-09 11:08:21   2016-01-09 11:13:59   \n",
      "2557844          2  2016-01-08 16:05:52   2016-01-08 16:26:48   \n",
      "\n",
      "          passenger_count  trip_distance  RatecodeID store_and_fwd_flag  \\\n",
      "10490098                1           2.20           1                  N   \n",
      "2864959                 2           1.01           1                  N   \n",
      "2557844                 1           4.06           1                  N   \n",
      "\n",
      "          PULocationID  DOLocationID  payment_type  fare_amount  extra  \\\n",
      "10490098           170            48             1         15.5    0.5   \n",
      "2864959            234           114             1          6.0    0.0   \n",
      "2557844            231           161             2         16.5    1.0   \n",
      "\n",
      "          mta_tax  tip_amount  tolls_amount  improvement_surcharge  \\\n",
      "10490098      0.5         1.2           0.0                    0.3   \n",
      "2864959       0.5         1.0           0.0                    0.3   \n",
      "2557844       0.5         0.0           0.0                    0.3   \n",
      "\n",
      "          total_amount congestion_surcharge airport_fee  trip_duration  \n",
      "10490098          18.0                 None        None         1477.0  \n",
      "2864959            7.8                 None        None          338.0  \n",
      "2557844           18.3                 None        None         1256.0  \n"
     ]
    }
   ],
   "source": [
    "# Verificar estructura del dataset\n",
    "print(\"üîç VERIFICANDO ESTRUCTURA DEL DATASET\")\n",
    "print(f\"Columnas disponibles: {list(df_sample.columns)}\")\n",
    "print(f\"Total columnas: {len(df_sample.columns)}\")\n",
    "print(\"\\nPrimeras 3 filas:\")\n",
    "print(df_sample.head(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f0d9d1",
   "metadata": {},
   "source": [
    "Descargar Archivo de Mapeo de Zonas (estoy aquiii)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (proyecto_venv)",
   "language": "python",
   "name": "proyecto_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
